# 思考

author: tedious

data: 2023-6-15

version: 0.0.0

## 分析

- user大小: 8 + 8 + 8 + 8 = 32字节
- world槽位数量: 200000 * 200000 = 40_000_000_000
- 若为二维数组world_status共需要申请(40_000_000_000 * 8)B, 约为320G内存.
- 实际世界状态大小为Users大小, 假设1000w用户在线(离线用户可以移至磁盘), 共消耗(32 * 10_000_000)B, 320M内存.

> 以下均在1000w在线情况下讨论.

## 按区域分片
如果按照区域来分片, 容易出现负载集中在某些区域(节点), 不能有效的负载均衡. 且用户跨区域会导致用户在服务器间转移. 我不太满意.

## 按用户分片
如果按照用户分片, 可以解决动态均衡的问题, 且用户不会出现跨服务器, 但如果使用类似ConHash的技术来分配的话, 会导致节点的区域属性被擦除, 进行query或aoe时无法精确调度任务. 我也不太满意

## 全节点冗余在线Users

计算任务按照Uid分配, 类似MapReduce的思想. 主节点负责派发任务并汇总结果更新状态, 从节点只负责完成计算任务.

此方案有以下问题:

1. 如何同步状态: 若每个Step全量同步世界状态, 则相当于每秒进/出口流量都为(50 * 320)M, 约15G(120Gbit), 有点大.
   1. 可以只同步变更, 但理论上每个用户状态都会变更.
   2. 存算分离. 增加存储节点, 只有存储节点与主节点之间同步世界状态(类似数据库主从同步), 计算节点不参与世界状态的同步, 不对外暴露. 虽然这样减少了集群总网络交互, 但存储节点的压力依然没得到缓解.
   3. 难道必须要分片???
2. 如何派发任务: 如果每次将需要计算的uid发送给节点, 相当于每秒主节点内网进/出口流量都为(50 * 320)M, 约15G(集群元数据只需要同步节点状态和用户或世界状态变更的指令, 忽略不计).
   - 可以每次只在计算任务变更后派发需要变更的数据, 减少主从节点间数据交互.
3. 如何降低延迟: 0.02s即20ms更新一次, 若我每20ms向计算节点下发一次计算任务, 可能会导致延迟高于20ms(网络传输延迟).
   1. 可以计算节点任务开始后就每隔20ms上报计算结果, 减少等待.
   2. 可以系统step领先实际世界1步, 主节点收集当前step内的状态变更, 在已经算好的Step2上进行修正并直接更新下一帧.
4. 如何高可用:
   1. 按照设计, 拥有全量世界状态的节点参与选举, 当主节点宕机后, 重新选举主节点维护世界运行.
   2. 当全部主节点宕机后, 可以将某计算节点提升为主节点. 并从全部计算节点收集数据, 拼装处完整世界状态(若计算节点也有宕机, 则可能会不全).